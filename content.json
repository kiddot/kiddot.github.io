{"meta":{"title":"Share","subtitle":null,"description":null,"author":"kiddot","url":"https://kiddot.github.io"},"pages":[{"title":"About","date":"2017-12-12T09:25:50.376Z","updated":"2017-12-12T08:40:40.637Z","comments":true,"path":"about/index.html","permalink":"https://kiddot.github.io/about/index.html","excerpt":"","text":""},{"title":"Categories","date":"2017-12-12T09:25:50.380Z","updated":"2017-12-12T08:40:40.637Z","comments":true,"path":"categories/index.html","permalink":"https://kiddot.github.io/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2017-12-12T09:25:50.380Z","updated":"2017-12-12T08:40:40.637Z","comments":true,"path":"tags/index.html","permalink":"https://kiddot.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"ArrayList和LinkedList","slug":"java集合/ArrayList和LinkedList","date":"2017-07-16T15:21:11.000Z","updated":"2017-12-14T06:28:19.813Z","comments":true,"path":"2017/07/16/java集合/ArrayList和LinkedList/","link":"","permalink":"https://kiddot.github.io/2017/07/16/java集合/ArrayList和LinkedList/","excerpt":"ArrayList和LinkedList","text":"ArrayList和LinkedList 区别 ArrayList是实现了基于动态数组的数据结构，而LinkedList是基于链表的数据结构； 对于随机访问get和set，ArrayList要优于LinkedList，因为LinkedList要移动指针； 对于添加和删除操作add和remove，一般大家都会说LinkedList要比ArrayList快，因为ArrayList要移动数据。但是实际情况并非这样，对于添加或删除，LinkedList和ArrayList并不能明确说明谁快谁慢 get ArrayList想要get(int index)元素时，直接返回index位置上的元素，而LinkedList需要通过for循环进行查找，虽然LinkedList已经在查找方法上做了优化，比如index &lt; size / 2，则从左边开始查找，反之从右边开始查找，但是还是比ArrayList要慢。这点是毋庸置疑的。 insert or remove ArrayList想要在指定位置插入或删除元素时，主要耗时的是System.arraycopy动作，会移动index后面所有的元素；LinkedList主耗时的是要先通过for循环找到index，然后直接插入或删除。这就导致了两者并非一定谁快谁慢。 主要有两个因素决定他们的效率，插入的数据量和插入的位置。 ArrayList扩容问题 ArrayList使用一个内置的数组来存储元素，这个数组的起始容量是10.当数组需要增长时，新的容量按如下公式获得：新容量=(旧容量3)/2+1，也就是说每一次容量大概会增长50%。这就意味着，如果你有一个包含大量元素的ArrayList对象，那么最终将有很大的空间会被浪费掉，这个浪费是由ArrayList的工作方式本身造成的。如果没有足够的空间来存放新的元素，数组将不得不被重新进行分配以便能够增加新的元素。*对数组进行重新分配，将会导致性能急剧下降。 回答梳理相同点都是java集合框架，都实现List接口 不同点 ArrayList是实现了基于动态数组的数据结构，它使用索引在数组中搜索和读取数据是很快的。Array获取数据的时间复杂度是O(1),但是要删除数据却是开销很大的，因为这需要重排数组中的所有数据。 LinkedList是基于链表的数据结构，对于添加和删除操作add和remove，一般大家都会说LinkedList要比ArrayList快，因为ArrayList要移动数据。但是实际情况并非这样，对于添加或删除，LinkedList和ArrayList并不能明确说明谁快谁慢 LinkedList需要更多的内存，因为ArrayList的每个索引的位置是实际的数据，而LinkedList中的每个节点中存储的是实际的数据和前后节点的位置。 效率ArrayList： ​ 1.内部的Object类型的影响 ，对于值类型来说，往ArrayList里面添加和修改元素，都会引起装箱和拆箱的操作，频繁的操作可能会影响一部分效率。 ​ 2.数组扩容 ，扩容操作往往会导致不必要的空间浪费，尽量去评估自己需要的容量 ​ 3.频繁的调用IndexOf、Contains等方法（Sort、BinarySearch等方法经过优化，不在此列）引起的效率损失 使用场景使用LinkList的场景： ​ 1.不会随机访问数据。因为如果你需要LinkedList中的第n个元素的时候，你需要从第一个元素顺序数到第n个数据，然后读取数据。 ​ 2.插入和删除元素的操作比较多，读取数据比较少的情况。因为插入和删除元素不涉及重排数据，所以它要比ArrayList要快。 扩展多线问题 ArrayList中的操作不是线程安全的。所以，建议在单线程中才使用ArrayList，而在多线程中可以选择CopyOnWriteArrayList。","categories":[{"name":"java集合","slug":"java集合","permalink":"https://kiddot.github.io/categories/java集合/"}],"tags":[{"name":"java集合","slug":"java集合","permalink":"https://kiddot.github.io/tags/java集合/"}]},{"title":"HashMap工作原理以及实现","slug":"java集合/HashMap工作原理及实现","date":"2017-07-16T14:22:11.000Z","updated":"2017-12-14T06:26:51.739Z","comments":true,"path":"2017/07/16/java集合/HashMap工作原理及实现/","link":"","permalink":"https://kiddot.github.io/2017/07/16/java集合/HashMap工作原理及实现/","excerpt":"知识储备：http://www.jianshu.com/p/bf1d7eee28d0（哈希算法总结） 1. 概述从本文你可以学习到：","text":"知识储备：http://www.jianshu.com/p/bf1d7eee28d0（哈希算法总结） 1. 概述从本文你可以学习到： 什么时候会使用HashMap？他有什么特点？ 你知道HashMap的工作原理吗？ 你知道get和put的原理吗？equals()和hashCode()的都有什么作用？ 你知道hash的实现吗？为什么要这样实现？ 如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？ 当我们执行下面的操作时： 123456789101112HashMap&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;();map.put(&quot;语文&quot;, 1);map.put(&quot;数学&quot;, 2);map.put(&quot;英语&quot;, 3);map.put(&quot;历史&quot;, 4);map.put(&quot;政治&quot;, 5);map.put(&quot;地理&quot;, 6);map.put(&quot;生物&quot;, 7);map.put(&quot;化学&quot;, 8);for(Entry&lt;String, Integer&gt; entry : map.entrySet()) &#123; System.out.println(entry.getKey() + &quot;: &quot; + entry.getValue());&#125; 运行结果是 政治: 5生物: 7历史: 4数学: 2化学: 8语文: 1英语: 3地理: 6 发生了什么呢？下面是一个大致的结构，希望我们对HashMap的结构有一个感性的认识： 在官方文档中是这样描述HashMap的： Hash table based implementation of the Map interface. This implementation provides all of the optional map operations, and permits null values and the null key. (The HashMap class is roughly equivalent to Hashtable, except that it is unsynchronized and permits nulls.) This class makes no guarantees as to the order of the map; in particular, it does not guarantee that the order will remain constant over time. 几个关键的信息：基于Map接口实现、允许null键/值、非同步、不保证有序(比如插入的顺序)、也不保证序不随时间变化。 2. 两个重要的参数在HashMap中有两个很重要的参数，容量(Capacity)和负载因子(Load factor) Initial capacity The capacity is the number of buckets in the hash table, The initial capacity is simply the capacity at the time the hash table is created. Load factor The load factor is a measure of how full the hash table is allowed to get before its capacity is automatically increased. 简单的说，Capacity就是buckets的数目，Load factor就是buckets填满程度的最大比例。如果对迭代性能要求很高的话不要把capacity设置过大，也不要把load factor设置过小。当bucket填充的数目（即hashmap中元素的个数）大于capacity*load factor时就需要调整buckets的数目为当前的2倍。 3. put函数的实现put函数大致的思路为： 对key的hashCode()做hash，然后再计算index; 如果没碰撞直接放到bucket里； 如果碰撞了，以链表的形式存在buckets后； 如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)，就把链表转换成红黑树； 如果节点已经存在就替换old value(保证key的唯一性) 如果bucket满了(超过load factor*current capacity)，就要resize。 具体代码的实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public V put(K key, V value) &#123; // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // tab为空则创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 计算index，并对null做处理 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 节点存在 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 该链为树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 该链为链表 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 写入 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 超过load factor*current capacity，resize if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 4. get函数的实现在理解了put之后，get就很简单了。大致思路如下： bucket里的第一个节点，直接命中； 如果有冲突，则通过key.equals(k)去查找对应的entry若为树，则在树中通过key.equals(k)查找，O(logn)；若为链表，则在链表中通过key.equals(k)查找，O(n)。 具体代码的实现如下： 12345678910111213141516171819202122232425262728public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 直接命中 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 未命中 if ((e = first.next) != null) &#123; // 在树中get if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 在链表中get do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 5. hash函数的实现在get和put的过程中，计算下标时，先对hashCode进行hash操作，然后再通过hash值进一步计算下标，如下图所示： 在对hashCode()计算hash时具体实现是这样的： 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 可以看到这个函数大概的作用就是：高16bit不变，低16bit和高16bit做了一个异或。其中代码注释是这样写的： Computes key.hashCode() and spreads (XORs) higher bits of hash to lower. Because the table uses power-of-two masking, sets of hashes that vary only in bits above the current mask will always collide. (Among known examples are sets of Float keys holding consecutive whole numbers in small tables.) So we apply a transform that spreads the impact of higher bits downward. There is a tradeoff between speed, utility, and quality of bit-spreading. Because many common sets of hashes are already reasonably distributed (so don’t benefit from spreading), and because we use trees to handle large sets of collisions in bins, we just XOR some shifted bits in the cheapest possible way to reduce systematic lossage, as well as to incorporate impact of the highest bits that would otherwise never be used in index calculations because of table bounds. 在设计hash函数时，因为目前的table长度n为2的幂，而计算下标的时候，是这样实现的(使用&amp;位操作，而非%求余)： 1(n - 1) &amp; hash 设计者认为这方法很容易发生碰撞。为什么这么说呢？不妨思考一下，在n - 1为15(0x1111)时，其实散列真正生效的只是低4bit的有效位，当然容易碰撞了。 因此，设计者想了一个顾全大局的方法(综合考虑了速度、作用、质量)，就是把高16bit和低16bit异或了一下。设计者还解释到因为现在大多数的hashCode的分布已经很不错了，就算是发生了碰撞也用O(logn)的tree去做了。仅仅异或一下，既减少了系统的开销，也不会造成的因为高位没有参与下标的计算(table长度比较小时)，从而引起的碰撞。 如果还是产生了频繁的碰撞，会发生什么问题呢？作者注释说，他们使用树来处理频繁的碰撞(we use trees to handle large sets of collisions in bins)，在JEP-180中，描述了这个问题： Improve the performance of java.util.HashMap under high hash-collision conditions by using balanced trees rather than linked lists to store map entries. Implement the same improvement in the LinkedHashMap class. 之前已经提过，在获取HashMap的元素时，基本分两步： 首先根据hashCode()做hash，然后确定bucket的index； 如果bucket的节点的key不是我们需要的，则通过keys.equals()在链中找。 在Java 8之前的实现中是用链表解决冲突的，在产生碰撞的情况下，进行get时，两步的时间复杂度是O(1)+O(n)。因此，当碰撞很厉害的时候n很大，O(n)的速度显然是影响速度的。 因此在Java 8中，利用红黑树替换链表，这样复杂度就变成了O(1)+O(logn)了，这样在n很大的时候，能够比较理想的解决这个问题，在Java 8：HashMap的性能提升一文中有性能测试的结果。 6. RESIZE的实现当put时，如果发现目前的bucket占用程度已经超过了Load Factor所希望的比例，那么就会发生resize。在resize的过程，简单的说就是把bucket扩充为2倍，之后重新计算index，把节点再放到新的bucket中。resize的注释是这样描述的： Initializes or doubles table size. If null, allocates in accord with initial capacity target held in field threshold. Otherwise, because we are using power-of-two expansion, the elements from each bin must either stay at same index, or move with a power of two offset in the new table. 大致意思就是说，当超过限制的时候会resize，然而又因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。 怎么理解呢？例如我们从16扩展为32时，具体的变化如下所示： 因此元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 因此，我们在扩充HashMap的时候，不需要重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”。可以看看下图为16扩充为32的resize示意图： 这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。 下面是代码的具体实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 超过最大值就不再扩充了，就只好随你碰撞去吧 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 计算新的resize上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 7. 总结我们现在可以回答开始的几个问题，加深对HashMap的理解： 1. 什么时候会使用HashMap？他有什么特点？是基于Map接口的实现，存储键值对时，它可以接收null的键值，是非同步的，HashMap存储着Entry(hash, key, value, next)对象。 2. 你知道HashMap的工作原理吗？通过hash的方法，通过put和get存储和获取对象。存储对象时，我们将K/V传给put方法时，它调用hashCode计算hash从而得到bucket位置，进一步存储，HashMap会根据当前bucket的占用情况自动调整容量(超过Load Facotr则resize为原来的2倍)。获取对象时，我们将K传给get，它调用hashCode计算hash从而得到bucket位置，并进一步调用equals()方法确定键值对。如果发生碰撞的时候，Hashmap通过链表将产生碰撞冲突的元素组织起来，在Java 8中，如果一个bucket中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，从而提高速度。 3. 你知道get和put的原理吗？equals()和hashCode()的都有什么作用？通过对key的hashCode()进行hashing，并计算下标( n-1 &amp; hash)，从而获得buckets的位置。如果产生碰撞，则利用key.equals()方法去链表或树中去查找对应的节点 4. 你知道hash的实现吗？为什么要这样实现？在Java 1.8的实现中，是通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在bucket的n比较小的时候，也能保证考虑到高低bit都参与到hash的计算中，同时不会有太大的开销。 5. 如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？如果超过了负载因子(默认0.75)，则会重新resize一个原来长度两倍的HashMap，并且重新调用hash方法。 关于Java集合的小抄中是这样描述的： 以Entry[]数组实现的哈希桶数组，用Key的哈希值取模桶数组的大小可得到数组下标。 插入元素时，如果两条Key落在同一个桶(比如哈希值1和17取模16后都属于第一个哈希桶)，Entry用一个next属性实现多个Entry以单向链表存放，后入桶的Entry将next指向桶当前的Entry。 查找哈希值为17的key时，先定位到第一个哈希桶，然后以链表遍历桶里所有元素，逐个比较其key值。 当Entry数量达到桶数量的75%时(很多文章说使用的桶数量达到了75%，但看代码不是)，会成倍扩容桶数组，并重新分配所有原来的Entry，所以这里也最好有个预估值。 取模用位运算(hash &amp; (arrayLength-1))会比较快，所以数组的大小永远是2的N次方， 你随便给一个初始值比如17会转为32。默认第一次放入元素时的初始值是16。 iterator()时顺着哈希桶数组来遍历，看起来是个乱序。 在JDK8里，新增默认为8的閥值，当一个桶里的Entry超过閥值，就不以单向链表而以红黑树来存放以加快Key的查找速度。 参考资料 HashMap的工作原理Java 8：HashMap的性能提升JEP 180: Handle Frequent HashMap Collisions with Balanced TreesConurrentHashMap和Hashtable的区别HashMap和Hashtable的区别 12345678910111213146.6 在Android中使用SparseArray代替HashMap官方推荐使用SparseArray([spɑ:s][ə&apos;reɪ],稀疏的数组)或者LongSparseArray代替HashMap。官方总结有一下几点好处：SparseArray使用基本类型(Primitive)中的int作为Key，不需要Pair&lt;K,V&gt;或者Entry&lt;K,V&gt;这样的包装类，节约了内存;SpareArray维护的是一个排序好的数组，使用二分查找数据，即O(log(N))，每次插入数据都要进行排序，同样耗时O(N)；而HashMap使用hashCode来加入/查找/删除数据，即O(N/buckets_size)；总的来说，就是SparseArray针对Android嵌入式设备进行了优化，牺牲了微小的时间性能，换取了更大的内存优化;同时它还有别的优化，比如对删除操作做了优化；如果你的数据非常少(实际上也是如此)，那么使用SpareArray也是不错的； （整体上）回答梳理1.基本的工作原理put 对key的hashCode()做hash，然后再计算index; 如果没碰撞直接放到bucket里； 如果碰撞了，以链表的形式存在buckets后； 如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)，就把链表转换成红黑树； 如果节点已经存在就替换old value(保证key的唯一性) 如果bucket满了(超过load factor*current capacity)，就要resize。 get bucket里的第一个节点，直接命中； 如果有冲突，则通过key.equals(k)去查找对应的entry 若为树，则在树中通过key.equals(k)查找，O(logn)； 若为链表，则在链表中通过key.equals(k)查找，O(n)。 2.hash函数的实现高16bit不变，低16bit和高16bit做了一个异或 3.Java 8中，利用红黑树替换链表java8中hashmap的性能提升：http://www.importnew.com/14417.html 4.resize、扩充、容量的变化5.Android中使用SparseArray代替HashMap","categories":[{"name":"java集合","slug":"java集合","permalink":"https://kiddot.github.io/categories/java集合/"}],"tags":[{"name":"java集合","slug":"java集合","permalink":"https://kiddot.github.io/tags/java集合/"}]},{"title":"GC方式","slug":"JVM/GC方式","date":"2017-07-14T14:22:11.000Z","updated":"2017-12-13T14:10:15.138Z","comments":true,"path":"2017/07/14/JVM/GC方式/","link":"","permalink":"https://kiddot.github.io/2017/07/14/JVM/GC方式/","excerpt":"GC方式","text":"GC方式 Minor GC新生代(由 Eden and Survivor 组成)的垃圾收集叫做Minor GC。注意： 当jvm 无法为新建对象分配内存空间的时候Minor GC被触发，例如新生代空间被占满。因此新生代空间占用率越高，Minor GC越频繁。 当空间被占满，它下面的所有对象都会被复制，而且堆顶指针从空闲空间的零位置移动。因此取代传统的标记清除压缩算法，去清理Eden区和Survivor区，因此Eden和Survivor区无内存碎片产生。 在Minor GC期间,实际上Tenured区被忽略，实际上Tenured区引用young区的对象被当作GC roots。在标记期间young区引用的Tenured区对象的对象会被忽略。 反对所有Minor GC都会触发“stop-the-world”这一观点。在大多数应用中，忽略”stop-the-world”停留时长。不可否认的是新生代中的一些对象被错误当成垃圾而不会被移动到Survivor/Old区。 Major GC ​ Major GC清理Tenured区，但是HotSpot VM发展了这么多年，外界对各种名词的解读已经完全混乱了且明确的定义，所以对于Major GC需要问清楚是指full GC还是old GC。 Full GC 收集整个堆，包括young gen、old gen、perm gen 针对HotSpot VM的实现，它里面的GC其实准确分类只有两大种： Partial GC：并不收集整个GC堆的模式 Young GC：只收集young gen的GC Old GC：只收集old gen的GC。只有CMS的concurrent collection是这个模式 Mixed GC：收集整个young gen以及部分old gen的GC。只有G1有这个模式 Full GC：收集整个堆，包括young gen、old gen、perm gen（如果存在的话）等所有部分的模式。 Major GC通常是跟full GC是等价的，收集整个GC堆。但因为HotSpot VM发展了这么多年，外界对各种名词的解读已经完全混乱了，当有人说“major GC”的时候一定要问清楚他想要指的是上面的full GC还是old GC。 young GC：当young gen中的eden区分配满的时候触发。注意young GC中有部分存活对象会晋升到old gen，所以young GC后old gen的占用量通常会有所升高。 full GC：当准备要触发一次young GC时，如果发现统计数据说之前young GC的平均晋升大小比目前old gen剩余的空间大，则不会触发young GC而是转为触发full GC（因为HotSpot VM的GC里，除了CMS的concurrent collection之外，其它能收集old gen的GC都会同时收集整个GC堆，包括young gen，所以不需要事先触发一次单独的young GC）；或者，如果有perm gen的话，要在perm gen分配空间但已经没有足够空间时，也要触发一次full GC；或者System.gc()、heap dump带GC，默认也是触发full GC。 Minor、Full GC触发条件Minor GC触发条件：当Eden区满时，触发Minor GC。 Full GC触发条件： （1）调用System.gc时，系统建议执行Full GC，但是不必然执行 （2）老年代空间不足 （3）方法区空间不足 （4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存 （5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小 回收对象 ​ 对于用可达性分析法搜索不到的对象，GC并不一定会回收该对象。要完全回收一个对象，至少需要经过两次标记的过程。 第一次标记：对于一个没有其他引用的对象，筛选该对象是否有必要执行finalize()方法，如果没有执行必要，则意味可直接回收。 第二次标记：如果被筛选判定位有必要执行，则会放入FQueue队列，并自动创建一个低优先级的finalize线程来执行释放操作。如果在一个对象释放前被其他对象引用，则该对象会被移除FQueue队列。 Full GC为什么那么慢 元数据区的回收算法效率低，虚拟机规范Class回收条件比较苛刻 Full GC回收新生代、老年代、元数据区/永久代。从这个角度讲，多回收了方法区，增加了总的回收耗时。 ​ 为什么Yong GC比Old GC慢？ 新生代复制算法比较快。Eden区回收时直接全部清空，存活的对象存放到内存容量比较小的s1，少了解决内存碎片整理 加上直接copy的速度，效率很高。 （牺牲时间换空间）老年代标记清除算法会导致内存碎片化，因此就引入了标记整理算法，执行完毕后，存活的对象会按序放置，移动对象的内存地址（重点），来解决碎片化，但是执行时间较长。 ​","categories":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/tags/jvm/"}]},{"title":"双亲委派模型","slug":"JVM/双亲委派模型","date":"2017-07-13T14:22:11.000Z","updated":"2017-12-13T13:57:21.076Z","comments":true,"path":"2017/07/13/JVM/双亲委派模型/","link":"","permalink":"https://kiddot.github.io/2017/07/13/JVM/双亲委派模型/","excerpt":"双亲委派模型","text":"双亲委派模型 JVM预定义的三种类型类加载器： 启动（Bootstrap）类加载器：是用本地代码实现的类装入器，它负责将 &lt;Java_Runtime_Home&gt;/lib下面的类库加载到内存中（比如rt.jar）。由于引导类加载器涉及到虚拟机本地实现细节，开发者无法直接获取到启动类加载器的引用，所以不允许直接通过引用进行操作。 标准扩展（Extension）类加载器：是由 Sun 的 ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将&lt; Java_Runtime_Home &gt;/lib/ext或者由系统变量 java.ext.dir指定位置中的类库加载到内存中。开发者可以直接使用标准扩展类加载器。 系统（System）类加载器：是由 Sun 的 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。它负责将系统类路径（CLASSPATH）中指定的类库加载到内存中。开发者可以直接使用系统类加载器。 双亲委派机制描述 : 某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父类加载器，依次递归，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。 几点思考 Java虚拟机的第一个类加载器是Bootstrap，这个加载器很特殊，它不是Java类，因此它不需要被别人加载，它嵌套在Java虚拟机内核里面，也就是JVM启动的时候Bootstrap就已经启动，它是用C++写的二进制代码（不是字节码），它可以去加载别的类。 ​ 这也是我们在测试时为什么发现System.class.getClassLoader()结果为null的原因，这并不表示System这个类没有类加载器，而是它的加载器比较特殊，是BootstrapClassLoader，由于它不是Java类，因此获得它的引用肯定返回null。 当Java虚拟机要加载一个类时，到底派出哪个类加载器去加载呢？ 首先当前线程的类加载器去加载线程中的第一个类（假设为类A）。注：当前线程的类加载器可以通过Thread类的getContextClassLoader()获得，也可以通过setContextClassLoader()自己设置类加载器。 如果类A中引用了类B，Java虚拟机将使用加载类A的类加载器去加载类B。 还可以直接调用ClassLoader.loadClass()方法来指定某个类加载器去加载某个类。 委托机制的意义 — 防止内存中出现多份同样的字节码 比如两个类A和类B都要加载System类： 如果不用委托而是自己加载自己的，那么类A就会加载一份System字节码，然后类B又会加载一份System字节码，这样内存中就出现了两份System字节码。 如果使用委托机制，会递归的向父类查找，也就是首选用Bootstrap尝试加载，如果找不到再向下。这里的System就能在Bootstrap中找到然后加载，如果此时类B也要加载System，也从Bootstrap开始，此时Bootstrap发现已经加载过了System那么直接返回内存中的System即可而不需要重新加载，这样内存中就只有一份System的字节码了。 是否能自己写一个System类？ 不可以，因为类加载采用委托机制，这样可以保证爸爸们优先，爸爸们能找到的类，儿子就没有机会加载。而System类是Bootstrap加载器加载的，就算自己重写，也总是使用Java系统提供的System，自己写的System类根本没有机会得到加载。 但是，我们可以自己定义一个类加载器来达到这个目的，为了避免双亲委托机制，这个类加载器也必须是特殊的。由于系统自带的三个类加载器都加载特定目录下的类，如果我们自己的类加载器放在一个特殊的目录，那么系统的加载器就无法加载，也就是最终还是由我们自己的加载器加载。","categories":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/tags/jvm/"}]},{"title":"类的加载","slug":"JVM/类的加载","date":"2017-07-13T10:51:22.000Z","updated":"2017-12-13T13:56:11.504Z","comments":true,"path":"2017/07/13/JVM/类的加载/","link":"","permalink":"https://kiddot.github.io/2017/07/13/JVM/类的加载/","excerpt":"类的加载","text":"类的加载 类加载到虚拟机内存到卸载的整个生命周期 整个生命周期包括:加载(Loading)、验证(Verification)、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using)和卸载(Unloading)7个阶段。其中验证、准备、解析3个部分统称为连接(Linking) 类加载的过程加载阶段加载有两种情况： ①当遇到new关键字，或者static关键字的时候就会发生（他们对应着对应的指令）如果在常量池中找不到对应符号引用时，就会发生加载 ②动态加载，当用反射方法（如class.forName(“类名”)），如果发现没有初始化，则要进行初始化。（注：加载的时候发现父类没有被加载，则要先加载父类） 在加载阶段,虚拟机需要完成以下3件事情: 1)通过一个类的全限定名来获取定义此类的二进制字节流。 2)将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 3)在内存中生成一个代表这个类的java.lang.Class对象,作为方法区这个类的各种数据的访问入口。 连接阶段 加载阶段与连接阶段的部分内容(如一部分字节码文件格式验证动作)是交叉进行的,加载阶段尚未完成,连接阶段可能已经开始,但这些夹在加载阶段之中进行的动作,仍然属于连接阶段的内容,这两个阶段的开始时间仍然保持着固定的先后顺序。 验证 验证是连接阶段的第一步,这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求,并且不会危害虚拟机自身的安全。 从整体上看,验证阶段大致上会完成下面4个阶段的检验动作:文件格式验证、元数据验证、字节码验证、符号引用验证。 文件格式验证 是否以魔数0xCAFEBABE开头。 主、次版本号是否在当前虚拟机处理范围之内。 常量池的常量中是否有不被支持的常量类型(检查常量tag标志)。 指向常量的各种索引值中是否有指向不存在的常量或不符合类型的常量。 CONSTANT_Utf8_info型的常量中是否有不符合UTF8编码的数据。 Class文件中各个部分及文件本身是否有被删除的或附加的其他信息。 元数据验证 这个类是否有父类(除了java.lang.Object之外,所有的类都应当有父类)。 这个类的父类是否继承了不允许被继承的类(被final修饰的类)。 如果这个类不是抽象类,是否实现了其父类或接口之中要求实现的所有方法。 类中的字段、方法是否与父类产生矛盾(例如覆盖了父类的final字段,或者出现不符合规则的方法重载,例如方法参数都一致,但返回值类型却不同等)。 字节码验证 … 符号引用验证 … 准备 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段,这些变量所使用的内存都将在方法区中进行分配。 这时候进行内存分配的仅包括类变量(被static修饰的变量),而不包括实例变量,实例变量将会在对象实例化时随着对象一起分配在Java堆中。其次,这里所说的初始值“通常情况”下是数据类型的零值 比如 1public static int value=123; ​ 变量value在准备阶段过后的初始值为0而不是123,因为这时候尚未开始执行任何Java方法,而把value赋值为123的putstatic指令是程序被编译后,存放于类构造器()方法之中,所以把value赋值为123的动作将在初始化阶段才会执行。 解析 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程 符号引用(Symbolic References):其实就是class文件常量池中的各种引用，他们按照一定规律指向了对应的类名，或者字段，但是并没有在内存中分配空间 直接引用(Direct References):直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。 初始化​ 简单讲就是执行对象的构造函数，给类的静态字段按照程序的意愿进行初始化，注意初始化的顺序。 ​ 此处的初始化由两个函数完成，一个是,初始化所有的类变量（静态变量），该函数不会初始化父类变量，还有一个是实例初始化函数,对类中实例对象进行初始化","categories":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/tags/jvm/"}]},{"title":"GC的三种收集方法","slug":"JVM/GC的三种收集方法","date":"2017-07-12T07:51:22.000Z","updated":"2017-12-13T13:54:37.233Z","comments":true,"path":"2017/07/12/JVM/GC的三种收集方法/","link":"","permalink":"https://kiddot.github.io/2017/07/12/JVM/GC的三种收集方法/","excerpt":"GC的三种收集方法","text":"GC的三种收集方法 标记清除分两个阶段 标记：首先标记出所有需要回收的对象 清除：在标记完成后统一回收所有被标记的对象。 特点： 回收特别快 两个不足： 效率问题，标记与清除两个过程效率不高 空间问题，标记清除之后会产生大量的不连续内存碎片 适合使用： 老年代的回收 标记整理分三个阶段： 标记：首先标记出所有需要回收的对象 整理：让所有存活的对象都向一边移动 清除：直接就清除端边界以外的内存 特点： 回收以后的空间连续 缺点： 整理要花一定时间 适合使用： 老年代的回收 复制算法思路： 将内存分成原始的相等的两份，每次只使用一部分 用完一部分，就将还存活的对象复制到另外一块内存 最后将要回收的内存全部清除 特点： 实现简单 运行高效 不足： 将原来的内存缩小了一半 在存活对象比较多时，要进行较多的复制操作，效率会变低 适合使用： 新生代的回收 优化收集方法对复制算法的优化​ 不是将两块内存分配同等大小，可以将存活率低的区域大一些，而让回收后存活的对象所占的区域小一些，不够的内存由老年代的内存来保证，这样复制算法的空闲的空间减少了。","categories":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/tags/jvm/"}]},{"title":"Java对象存活分析","slug":"JVM/Java对象存活分析","date":"2017-07-11T03:51:22.000Z","updated":"2017-12-13T13:53:34.178Z","comments":true,"path":"2017/07/11/JVM/Java对象存活分析/","link":"","permalink":"https://kiddot.github.io/2017/07/11/JVM/Java对象存活分析/","excerpt":"Java对象存活分析 ​ 判断对象是否存活有两种比较常见的方法：引用计数法与可达性分析算法。","text":"Java对象存活分析 ​ 判断对象是否存活有两种比较常见的方法：引用计数法与可达性分析算法。 引用计数法 ​ 引用计数法的逻辑非常简单，但是存在问题，java并不采用这种方式进行对象存活判断。 ​ 引用计数法的逻辑是：在堆中存储对象时，在对象头处维护一个counter计数器，如果一个对象增加了一个引用与之相连，则将counter++。如果一个引用关系失效则counter–。如果一个对象的counter变为0，则说明该对象已经被废弃，不处于存活状态。 这种方法来标记对象的状态会存在很多问题： jdk从1.2开始增加了多种引用方式：软引用、弱引用、虚引用，且在不同引用情况下程序应进行不同的操作。如果我们只采用一个引用计数法来计数无法准确的区分这么多种引用的情况。 除了引用计数法无法解决多种类型引用的问题，循环持有问题才是致命的问题。比如: 如果一个对象A持有对象B，而对象B也持有一个对象A，那发生了类似操作系统中死锁的循环持有，这种情况下A与B的counter恒大于1，会使得GC永远无法回收这两个对象。 可达性分析算法​ 这个算法的基本思路就是通过一系列名为GC Roots的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。 如下情况的对象可以作为GC Roots： 虚拟机栈(栈桢中的本地变量表)中的引用的对象 方法区中的类静态属性引用的对象 方法区中的常量引用的对象 本地方法栈中JNI（Native方法）的引用的对象 HotSpot虚拟机如何实现可达性算法？使用OopMap记录并枚举根节点 HotSpot首先需要枚举所有的GC Roots根节点，虚拟机栈的空间不大，遍历一次的时间或许可以接受，但是方法区的空间很可能就有数百兆，遍历一次需要很久。更加关键的是，当我们遍历所有GC Roots根节点时，我们需要暂停所有用户线程，因为我们需要一个此时此刻的”虚拟机快照”，如果我们不暂停用户线程，那么虚拟机仍处于运行状态，我们无法确保能够正确遍历所有的根节点。所以此时的时间开销过大更是我们不能接受的。 基于这种情况，HotSpot实现了一种叫做OopMap的数据结构，这种数据结构在类加载完成时把对象内的偏移量是什么类型计算出，并且存放下位置，当需要遍历根结点时访问所有OopMap即可。 用安全点Safepoint约束根节点 如果将每个符合GC Roots条件的对象都存放进入OopMap中，那么OopMap也会变得很大，而且其中很多对象很可能会发生一些变化，这些变化使得维护这个映射表很困难。实际上，HotSpot并没有为每一个对象都创建OopMap，只在特定的位置上创建了这些信息，这些位置称为安全点（Safepoints）。 为了保证虚拟机中安全点的个数不算太多也不是太少，主要决定安全点是否被建立的因素是时间。当进行了耗时的操作时，比如方法调用、循环跳转等时会产生安全点。","categories":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/tags/jvm/"}]},{"title":"对象的创建、布局与访问","slug":"JVM/对象的创建、布局与访问","date":"2017-06-30T10:51:22.000Z","updated":"2017-12-13T13:57:58.632Z","comments":true,"path":"2017/06/30/JVM/对象的创建、布局与访问/","link":"","permalink":"https://kiddot.github.io/2017/06/30/JVM/对象的创建、布局与访问/","excerpt":"对象的创建、布局与访问","text":"对象的创建、布局与访问 一、创建1new People(); 这行代码背后的JVM操作： 类加载检查​ 检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类的加载过程 为对象分配内存 ​ 对象所需内存的大小在类加载完成后便完全确定，为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来 ​ 根据Java堆中是否有规整有两种内存的分配方式： 指针分配 Java堆中的内存是规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，分配内存也就是把指针向空闲空间那边移动一段与内存大小相等的距离。 空闲列表 Java堆中的内存不是规整的，已使用的内存和空闲的内存相互交错。虚拟机必须维护一张列表，记录哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录。 分配内存时解决并发问题的两种方案 ​ 对象创建在虚拟机中时非常频繁的行为，即使是仅仅修改一个指针指向的位置，在并发情况下也并不是线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况 对分配内存空间的动作进行同步处理 把内存分配的动作按照线程划分为在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲(TLAB) 内存空间初始化 虚拟机将分配到的内存空间都初始化为零值（不包括对象头）,如果使用了TLAB，这一工作过程也可以提前至TLAB分配时进行。 内存空间初始化保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 对象设置​ 虚拟机对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息存放在对象的对象头之中。 在上面的工作都完成之后，从虚拟机的角度看，一个新的对象已经产生了。 但是从Java程序的角度看，对象的创建才刚刚开始方法还没有执行，所有的字段都还是零。 一般来说，执行new指令之后会接着执行方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算产生出来。 二、对象内存的布局 ​ 在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头(Header)、实例数据(Instance Data)和对齐填充(Padding)。 对象头 HotSpot虚拟机的对象头包括两部分信息 第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等 另外一个部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 实例数据 ​ 实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。 对齐填充 ​ 对齐填充并不是必然存在的，也没有特定的含义，仅仅起着占位符的作用。 三、对象的访问定位 ​ 建立对象是为了使用对象，我们的Java程序需要通过栈上的引用数据来操作堆上的具体对象。 目前主流的访问方式有使用句柄和直接指针两种。 使用句柄​ 如果使用句柄的话，那么Java堆中将会划分出一块内存来作为句柄池，引用中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。 直接指针​ 如果使用直接指针访问，那么Java堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而引用中存储的直接就是对象地址。 优势：速度更快，节省了一次指针定位的时间开销。（由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是非常可观的执行成本）","categories":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/tags/jvm/"}]},{"title":"Java堆空间的分区","slug":"JVM/Java堆空间的分区","date":"2017-06-28T12:51:11.000Z","updated":"2017-12-13T13:57:38.968Z","comments":true,"path":"2017/06/28/JVM/Java堆空间的分区/","link":"","permalink":"https://kiddot.github.io/2017/06/28/JVM/Java堆空间的分区/","excerpt":"Java堆空间的分区","text":"Java堆空间的分区 Eden区 Eden区位于Java堆的年轻代，是新对象分配内存的地方，由于堆是所有线程共享的，因此在堆上分配内存需要加锁。而Sun JDK为提升效率，会为每个新建的线程在Eden上分配一块独立的空间由该线程独享，这块空间称为TLAB（Thread Local Allocation Buffer）。在TLAB上分配内存不需要加锁，因此JVM在给线程中的对象分配内存时会尽量在TLAB上分配。如果对象过大或TLAB用完，则仍然在堆上进行分配。如果Eden区内存也用完了，则会进行一次Minor GC（young GC）。 Survival from to Survival区与Eden区相同都在Java堆的年轻代。Survival区有两块，一块称为from区，另一块为to区，这两个区是相对的，在发生一次Minor GC后，from区就会和to区互换。在发生Minor GC时，Eden区和Survivalfrom区会把一些仍然存活的对象复制进Survival to区，并清除内存。Survival to区会把一些存活得足够旧的对象移至年老代。 老年代 老年代里存放的都是存活时间较久的，大小较大的对象，因此年老代使用标记整理算法。当年老代容量满的时候，会触发一次Major GC（full GC），回收年老代和年轻代中不再被使用的对象资源。 扩展一一、逃逸分析和TLAB 扩展：new出来的对象并不都是被分配在堆上。但是Java中的逃逸分析和TLAB，可以认为一定会分配在堆上。 TLAB： JVM在内存新生代Eden Space中开辟了一小块线程私有的区域，称作TLAB（Thread-local allocation buffer）。默认设定为占用Eden Space的1%。在Java程序中很多对象都是小对象且用过即丢，它们不存在线程共享也适合被快速GC，所以对于小对象通常JVM会优先分配在TLAB上，并且TLAB上的分配由于是线程私有所以没有锁开销。 二、Java对象分配的过程 编译器通过逃逸分析，确定对象是在栈上分配还是在堆上分配。如果是在堆上分配，则进入选项2. 如果tlab_top + size &lt;= tlab_end，则在在TLAB上直接分配对象并增加tlab_top 的值，如果现有的TLAB不足以存放当前对象则3. 重新申请一个TLAB，并再次尝试存放当前对象。如果放不下，则4. 在Eden区加锁（这个区是多线程共享的），如果eden_top + size &lt;= eden_end则将对象存放在Eden区，增加eden_top 的值，如果Eden区不足以存放，则5. 执行一次Young GC（minor collection）。 经过Young GC之后，如果Eden区任然不足以存放当前对象，则直接分配到老年代。 扩展二JVM 新生代为何需要两个 Survivor 空间？为什么不是0个 Survivor 空间？ 如果没有 Survivor 空间的话，垃圾收集将会怎样进行：一遍新生代 gc 过后，不管三七二十一，活着的对象全部进入老年代，即便它在接下来的几次 gc 过程中极有可能被回收掉。这样的话老年代很快被填满， Full GC 的频率大大增加。我们知道，老年代一般都会被规划成比新生代大很多，对它进行垃圾收集会消耗比较长的时间；如果收集的频率又很快的话，那就更糟糕了。基于这种考虑，虚拟机引进了“幸存区”的概念：如果对象在某次新生代 gc 之后任然存活，让它暂时进入幸存区；以后每熬过一次 gc ，让对象的年龄＋1，直到其年龄达到某个设定的值（比如15岁）， JVM 认为它很有可能是个“老不死的”对象，再呆在幸存区没有必要（而且老是在两个幸存区之间反复地复制也需要消耗资源），才会把它转移到老年代。 设置 Survivor 空间的目的是让那些中等寿命的对象尽量在 Minor GC 时被干掉，最终在总体上减少虚拟机的垃圾收集过程对用户程序的影响。 为什么不是1个 Survivor 空间？ 新生代一般都采用复制算法进行垃圾收集。原始的复制算法是把一块内存一分为二， gc 时把存活的对象从一块空间（From space）复制到另外一块空间（To space），再把原先的那块内存（From space）清理干净，最后调换 From space 和 To space 的逻辑角色 在 HotSpot 虚拟机里， Eden 空间和 Survivor 空间默认的比例是 8:1 。我们来看看在只有一个 Survivor 空间的情况下，这个 8:1 会有什么问题。此处为了方便说明，我们假设新生代一共为 9 MB 。对象优先在 Eden 区分配，当 Eden 空间满 8 MB 时，触发第一次 Minor GC 。比如说有 0.5 MB 的对象存活，那这 0.5 MB 的对象将由 Eden 区向 Survivor 区复制。这次 Minor GC 过后， Eden 区被清理干净， Survivor 区被占用了 0.5 MB ，还剩 0.5 MB 。到这里一切都很美好，但问题马上就来了：从现在开始所有对象将会在这剩下的 0.5 MB 的空间上被分配，很快就会发现空间不足，于是只好触发下一次 Minor GC 。可以看出在这种情况下，当 Survivor 空间作为对象“出生地”的时候，很容易触发 Minor GC ，这种 8:1 的不对称分配不但没能在总体上降低 Minor GC 的频率，还会把 gc 的时间间隔搞得很不平均。 为什么2个 Survivor 空间可以达到要求？ 我们把 Eden : From Survivor : To Survivor 空间大小设成 8 : 1 : 1 ，对象总是在 Eden 区出生， From Survivor 保存当前的幸存对象， To Survivor 为空。一次 gc 发生后： 1）Eden 区活着的对象 ＋ From Survivor 存储的对象被复制到 To Survivor ； 2) 清空 Eden 和 From Survivor ； 3) 颠倒 From Survivor 和 To Survivor 的逻辑关系： From 变 To ， To 变 From 。","categories":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/tags/jvm/"}]},{"title":"JVM内存模型以及分区","slug":"JVM/JVM内存模型以及分区","date":"2017-06-28T10:51:22.000Z","updated":"2017-12-13T13:57:49.856Z","comments":true,"path":"2017/06/28/JVM/JVM内存模型以及分区/","link":"","permalink":"https://kiddot.github.io/2017/06/28/JVM/JVM内存模型以及分区/","excerpt":"JVM内存模型以及分区","text":"JVM内存模型以及分区 ​ 学习过C语言都知道，C编译器在划分内存区域的时候经常将管理的区域划分为数据段和代码段，数据段包括堆、栈以及静态数据区。那在Java语言当中，内存又是如何划分的？ ​ 我们在谈Java内存区域划分的时候事实上是指JVM内存区域划分。在讨论JVM内存区域划分之前，先来看一下Java程序具体执行的过程： Java源代码文件(.java后缀)会被Java编译器编译为字节码文件(.class后缀) JVM中的类加载器加载各个类的字节码文件 加载完毕之后，交由JVM执行引擎执行 ​ 在整个程序执行过程中，JVM会用一段空间来存储程序执行期间需要用到的数据和相关信息，这段空间一般被称作为Runtime Data Area（运行时数据区），也就是我们常说的JVM内存 运行时数据区包括哪几部分，以及存储了哪些数据程序计数器 ​ 在汇编语言中，程序计数器是指CPU中的寄存器，它保存的是程序当前执行的指令的地址（也可以说保存下一条指令的所在存储单元的地址），当CPU需要执行指令时，需要从程序计数器中得到当前需要执行的指令所在存储单元的地址，然后根据得到的地址获取到指令，在得到指令之后，程序计数器便自动加1或者根据转移指针得到下一条指令的地址，如此循环，直至执行完所有的指令。 ​ JVM中的程序计数器并不像汇编语言中的程序计数器一样是物理概念上的CPU寄存器，但是JVM中的程序计数器的功能跟汇编语言中的程序计数器的功能在逻辑上是等同的，也就是说是用来指示 执行哪条指令的。 ​ 由于在JVM中，多线程是通过线程轮流切换来获得CPU执行时间的，因此，在任一具体时刻，一个CPU的内核只会执行一条线程中的指令，因此，为了能够使得每个线程都在线程切换后能够恢复在切换之前的程序执行位置，每个线程都需要有自己独立的程序计数器，并且不能互相被干扰，否则就会影响到程序的正常执行次序。因此，可以这么说，程序计数器是每个线程所私有的。 ​ 在JVM规范中规定，如果线程执行的是非native方法，则程序计数器中保存的是当前需要执行的指令的地址；如果线程执行的是native方法，则程序计数器中的值是undefined。 ​ 由于程序计数器中存储的数据所占空间的大小不会随程序的执行而发生改变，因此，对于程序计数器是不会发生内存溢出现象(OutOfMemory) Java栈 与C语言中的数据段中的栈类似 ​ Java栈是Java方法执行的内存模型 ​ Java栈中存放的是一个个的栈帧，每个栈帧对应一个被调用的方法，在栈帧中包括局部变量表(Local Variables)、操作数栈(Operand Stack)、指向当前方法所属的类的运行时常量池（运行时常量池的概念在方法区部分会谈到）的引用(Reference to runtime constant pool)、方法返回地址(Return Address)和一些额外的附加信息。当线程执行一个方法时，就会随之创建一个对应的栈帧，并将建立的栈帧压栈。当方法执行完毕之后，便会将栈帧出栈。 ​ 由此可以得出三个结论：一、线程当前执行的方法对应的栈帧必定位于Java栈的顶部。 二、因为栈的空间是有限的，所以在使用递归的时候，会因为执行方法的次数太多导致栈帧不足以存放在栈中而发生栈内存溢出现象，即栈溢出。三、栈空间的分配与释放都是由系统自动实施管理的。 局部变量表 用来存储方法中的局部变量。对于基本数据类型的变量，则直接存储它的值，对于引用类型的变量，则存的是指向对象的引用。局部变量表的大小在编译器就可以确定其大小了，因此在程序执行期间局部变量表的大小是不会改变的 操作数栈 协助完成程序中所有的计算过程 指向运行时常量池的引用 在方法执行的过程中有可能需要用到类中的常量，所以必须要有一个引用指向运行时常量 方法返回地址 当一个方法执行完毕之后，要返回之前调用它的地方，因此在栈帧中必须保存一个方法返回地址 ps：每个线程都会有一个自己的Java栈 本地方法栈 ​ 本地方法栈与Java栈的作用和原理非常相似。区别是Java栈是为执行Java方法服务的，而本地方法栈则是为执行本地方法（Native Method）服务的。 ​ 在JVM规范中，并没有对本地方发展的具体实现方法以及数据结构作强制规定，虚拟机可以自由实现它。在HotSopt虚拟机中直接就把本地方法栈和Java栈合二为一。 堆 ​ 在C语言中，堆这部分空间是唯一一个程序员可以管理的内存区域。但是在java中基本不用关心空间的释放问题，因为Java的GC机制。这部分空间也是Java垃圾收集器管理的主要区域。 ​ Java中的堆是用来存储对象本身的以及数组（数组引用是存放在Java栈中的）。 ​ 堆是被所有线程共享的，在JVM中只有一个堆。 方法区 与堆一样，是被线程共享的区域 ​ 在方法区中，存储了每个类的信息（包括类的名称、方法信息、字段信息）、静态变量、常量以及编译器编译后的代码等。 ​ 在Class文件中除了类的字段、方法、接口等描述信息外，还有一项信息是常量池，用来存储编译期间生成的字面量和符号引用。 ​ 运行时常量池,是方法区中非常重要的部分，它是每一个类或接口的常量池的运行时表示形式，在类和接口被加载的JVM后，对应的运行时常量池就被创建出来。但不仅是Class文件常量池中的内容才能进入运行时常量池，在运行期间也可将新的常量放入运行时常量池中，比如String的intern方法。 在JVM规范中，没有强制要求方法区必须实现垃圾回收。所以许多人称之为永久代。 扩展：JDK7数据存储在永久代的部分数据就已经转移到了Java Heap或者是 Native Heap。JDK8永久代的废弃。 为什么要废除永久代？ 永久代内存经常不够用或发生内存泄露，爆出异常java.lang.OutOfMemoryError: PermGen。由于方法区主要存储类的相关信息，所以对于动态生成类的情况比较容易出现永久代的内存溢出。 字符串存在永久代中，容易出现性能问题和内存溢出。 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。 ​ 用什么代替永久代 元空间。元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。 JDK8中类加载（方法区的功能）已经不在永久代PerGem中了，而是Metaspace（元空间）中","categories":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://kiddot.github.io/tags/jvm/"}]}]}